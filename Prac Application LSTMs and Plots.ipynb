{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba3f0054",
   "metadata": {},
   "source": [
    "## Practical Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070bbff6",
   "metadata": {},
   "source": [
    "### Practical Applicaiton: Hybrid Method (Shorter Time Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a17343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "data_path = \"derived/final_merged_for_lstm.csv\"\n",
    "df = pd.read_csv(data_path, parse_dates=[\"Date\"])\n",
    "\n",
    "df = df.drop(columns=[col for col in ['key_0', 'Date_sent'] if col in df.columns]) # Clean Up Columns\n",
    "\n",
    "for col in df.columns: # Ensuring all columns except Date are numeric\n",
    "    if col not in ['Date']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Feature Engineering\n",
    "exclude_cols = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume'] # Remove prices and volume\n",
    "feature_cols = ['Return', 'VIX', 'Sentiment']\n",
    "N_LAGS = 2 #lagged features\n",
    "for lag in range(1, N_LAGS+1):\n",
    "    df[f\"Return_lag{lag}\"] = df[\"Return\"].shift(lag)\n",
    "    df[f\"Sentiment_lag{lag}\"] = df[\"Sentiment\"].shift(lag)\n",
    "feature_cols += [f\"Return_lag{lag}\" for lag in range(1, N_LAGS+1)]\n",
    "feature_cols += [f\"Sentiment_lag{lag}\" for lag in range(1, N_LAGS+1)]\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Train/val/test split by time\n",
    "TRAIN_END = date(2022, 12, 31)\n",
    "VAL_END = date(2024, 5, 31)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df_train = df[df[\"Date\"] <= pd.to_datetime(TRAIN_END)]\n",
    "df_val = df[(df[\"Date\"] > pd.to_datetime(TRAIN_END)) & (df[\"Date\"] <= pd.to_datetime(VAL_END))]\n",
    "df_test = df[df[\"Date\"] > pd.to_datetime(VAL_END)]\n",
    "\n",
    "# Scaling \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(df_train[feature_cols])\n",
    "X_val = scaler.transform(df_val[feature_cols])\n",
    "X_test = scaler.transform(df_test[feature_cols])\n",
    "y_train = df_train[\"Return\"].values\n",
    "y_val = df_val[\"Return\"].values\n",
    "y_test = df_test[\"Return\"].values\n",
    "\n",
    "# Creating LSTM Sequences\n",
    "SEQ_LEN = 5\n",
    "def create_sequences(x, y, seq_len):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(x) - seq_len):\n",
    "        xs.append(x[i : i + seq_len])\n",
    "        ys.append(y[i + seq_len])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, SEQ_LEN)\n",
    "X_val_seq, y_val_seq = create_sequences(X_val, y_val, SEQ_LEN)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, SEQ_LEN)\n",
    "\n",
    "# LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(50, input_shape=(SEQ_LEN, X_train_seq.shape[2])),\n",
    "    Dense(1),\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "print(\"Training LSTM …\")\n",
    "model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating …\")\n",
    "pred_test = model.predict(X_test_seq).flatten()\n",
    "rmse = np.sqrt(mean_squared_error(y_test_seq, pred_test))\n",
    "print(f\"Test RMSE: {rmse:.6f}\")\n",
    "\n",
    "# Directional accuracy\n",
    "actual_dir = (y_test_seq > 0)\n",
    "pred_dir = (pred_test > 0)\n",
    "acc = accuracy_score(actual_dir, pred_dir)\n",
    "print(f\"Directional accuracy: {acc:.2%}\")\n",
    "\n",
    "df_out = df_test.iloc[SEQ_LEN:].copy().reset_index(drop=True)\n",
    "df_out[\"Predicted_Return\"] = pred_test\n",
    "df_out.to_csv(\"derived/lstm_prac_test_predictions.csv\", index=False)\n",
    "\n",
    "print(df_out[[\"Date\", \"Return\", \"Predicted_Return\"]].head())\n",
    "print(\"Final LSTM model summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba7a277",
   "metadata": {},
   "source": [
    "### Practical Applicaiton: FinBERT-only Method (Shorter Time Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a14048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "data_path = \"derived/final_merged_FinBERT_for_lstm.csv\"\n",
    "df = pd.read_csv(data_path, parse_dates=[\"Date\"])\n",
    "\n",
    "df = df.drop(columns=[col for col in ['key_0', 'Date_sent'] if col in df.columns]) # Clean columns \n",
    "\n",
    "for col in ['Close', 'High', 'Low', 'Open', 'Volume']: # Removing non-numeric entry columns\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "if \"VIX\" in df.columns:\n",
    "    df[\"VIX\"] = pd.to_numeric(df[\"VIX\"], errors='coerce')\n",
    "\n",
    "for col in df.columns: # Set all except 'Date' are numeric\n",
    "    if col != 'Date':\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Feature Engineering\n",
    "N_LAGS = 2\n",
    "for lag in range(1, N_LAGS+1):\n",
    "    df[f\"Return_lag{lag}\"] = df[\"Return\"].shift(lag)\n",
    "    df[f\"FinBERT_score_lag{lag}\"] = df[\"FinBERT_score\"].shift(lag)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Train/val/test split \n",
    "TRAIN_END = date(2022, 12, 31)\n",
    "VAL_END = date(2024, 5, 31)\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df_train = df[df[\"Date\"] <= pd.to_datetime(TRAIN_END)]\n",
    "df_val = df[(df[\"Date\"] > pd.to_datetime(TRAIN_END)) & (df[\"Date\"] <= pd.to_datetime(VAL_END))]\n",
    "df_test = df[df[\"Date\"] > pd.to_datetime(VAL_END)]\n",
    "\n",
    "# Features and Scaling\n",
    "FEATURES = ['Close', 'High', 'Low', 'Open', 'Volume', 'VIX', 'FinBERT_score'] + \\\n",
    "           [f\"Return_lag{lag}\" for lag in range(1, N_LAGS+1)] + \\\n",
    "           [f\"FinBERT_score_lag{lag}\" for lag in range(1, N_LAGS+1)]\n",
    "X_train = df_train[FEATURES].astype(np.float32).values\n",
    "X_val = df_val[FEATURES].astype(np.float32).values\n",
    "X_test = df_test[FEATURES].astype(np.float32).values\n",
    "y_train = df_train[\"Return\"].values\n",
    "y_val = df_val[\"Return\"].values\n",
    "y_test = df_test[\"Return\"].values\n",
    "\n",
    "# Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create LSTM sequences (window=5)\n",
    "SEQ_LEN = 5\n",
    "def create_sequences(x, y, seq_len):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(x) - seq_len):\n",
    "        xs.append(x[i : i + seq_len])\n",
    "        ys.append(y[i + seq_len])\n",
    "    return np.array(xs), np.array(ys)\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, SEQ_LEN)\n",
    "X_val_seq, y_val_seq = create_sequences(X_val, y_val, SEQ_LEN)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, SEQ_LEN)\n",
    "\n",
    "print(f\"Train samples: {X_train_seq.shape[0]}, Val: {X_val_seq.shape[0]}, Test: {X_test_seq.shape[0]}\")\n",
    "\n",
    "# LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(50, input_shape=(SEQ_LEN, X_train_seq.shape[2])),\n",
    "    Dense(1),\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "print(\"Training LSTM …\")\n",
    "model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"Evaluating …\") # Evaluation\n",
    "pred_test = model.predict(X_test_seq).flatten()\n",
    "rmse = np.sqrt(mean_squared_error(y_test_seq, pred_test))\n",
    "print(f\"Test RMSE: {rmse:.6f}\")\n",
    "\n",
    "actual_dir = (y_test_seq > 0) # Directional accuracy\n",
    "pred_dir = (pred_test > 0)\n",
    "acc = accuracy_score(actual_dir, pred_dir)\n",
    "print(f\"Directional accuracy: {acc:.2%}\")\n",
    "\n",
    "df_test = df_test.iloc[SEQ_LEN:].copy()  # aligning with y_test_seq\n",
    "df_test[\"Predicted_Return\"] = pred_test\n",
    "df_test.to_csv(\"derived/lstm_prac_FinBERT_only_test_predictions.csv\", index=False)\n",
    "\n",
    "print(df_test[[\"Date\", \"Return\", \"Predicted_Return\"]].head())\n",
    "print(\"Final LSTM model summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d895d48e",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, accuracy_score,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from scipy.stats import norm\n",
    "\n",
    "df_gpt = pd.read_csv(\"derived/lstm_prac_test_predictions.csv\", parse_dates=[\"Date\"])\n",
    "df_fbert = pd.read_csv(\"derived/lstm_prac_FinBERT_only_test_predictions.csv\", parse_dates=[\"Date\"])\n",
    "market_df = pd.read_csv(\"sp500_vix_data.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "df = pd.DataFrame({ # Align data by date\n",
    "    \"Date\": df_gpt[\"Date\"],\n",
    "    \"Market_Return\": df_gpt[\"Return\"],\n",
    "    \"LSTM_GPT4\": df_gpt[\"Predicted_Return\"],\n",
    "    \"LSTM_FinBERT\": df_fbert[\"Predicted_Return\"],\n",
    "})\n",
    "df = df.merge(market_df[[\"Date\", \"Return\", \"VIX\"]].rename(columns={\"Return\": \"Market_True_Return\"}), on=\"Date\", how=\"left\")\n",
    "df[\"VIX\"] = pd.to_numeric(df[\"VIX\"], errors=\"coerce\")\n",
    "\n",
    "def trading_signal_returns(true_returns, predicted_returns): # Signal-based trading returns\n",
    "    signal = np.where(predicted_returns > 0, 1, -1)\n",
    "    return signal * true_returns\n",
    "\n",
    "def compute_all_metrics(true_returns, predicted_returns, rolling_window=60): # Computing all metrics for each model (with rolling mean/std)\n",
    "    if len(true_returns) == 0 or len(predicted_returns) == 0:\n",
    "        raise ValueError(\"Empty input arrays! Check your mask and input data.\")\n",
    "    mse = mean_squared_error(true_returns, predicted_returns)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(true_returns, predicted_returns)\n",
    "\n",
    "    true_up = (true_returns > 0).astype(int)\n",
    "    pred_up = (predicted_returns > 0).astype(int)\n",
    "\n",
    "    acc = accuracy_score(true_up, pred_up)\n",
    "    prec = precision_score(true_up, pred_up, zero_division=0)\n",
    "    rec = recall_score(true_up, pred_up, zero_division=0)\n",
    "    f1 = f1_score(true_up, pred_up, zero_division=0)\n",
    "    try:\n",
    "        roc = roc_auc_score(true_up, predicted_returns)\n",
    "    except:\n",
    "        roc = np.nan\n",
    "\n",
    "    cm = confusion_matrix(true_up, pred_up)\n",
    "    strat_returns = trading_signal_returns(true_returns, predicted_returns)\n",
    "    cum_return = np.cumprod(1 + strat_returns)[-1] - 1 if len(strat_returns) > 0 else np.nan\n",
    "    sharpe = np.mean(strat_returns) / (np.std(strat_returns) + 1e-9) * np.sqrt(252)\n",
    "    roll_sharpe = pd.Series(strat_returns).rolling(rolling_window).apply(\n",
    "        lambda x: np.mean(x) / (np.std(x) + 1e-9) * np.sqrt(252), raw=True)\n",
    "    roll_acc = pd.Series(pred_up == true_up).rolling(rolling_window).mean()\n",
    "    roll_cum_return = (1 + pd.Series(strat_returns)).cumprod() - 1\n",
    "    rolling_sharpe_mean, rolling_sharpe_std = roll_sharpe.mean(), roll_sharpe.std()\n",
    "    rolling_acc_mean, rolling_acc_std = roll_acc.mean(), roll_acc.std()\n",
    "    return {\n",
    "        \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae,\n",
    "        \"Direction_Acc\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"ROC_AUC\": roc,\n",
    "        \"Sharpe\": sharpe, \"Cumulative_Return\": cum_return,\n",
    "        \"Rolling_Sharpe_Mean\": rolling_sharpe_mean, \"Rolling_Sharpe_Std\": rolling_sharpe_std,\n",
    "        \"Rolling_Acc_Mean\": rolling_acc_mean, \"Rolling_Acc_Std\": rolling_acc_std,\n",
    "        \"Confusion_Matrix\": cm,\n",
    "        \"Rolling_Sharpe\": roll_sharpe,\n",
    "        \"Rolling_Acc\": roll_acc,\n",
    "        \"Rolling_CumReturn\": roll_cum_return,\n",
    "        \"Signal_Returns\": strat_returns\n",
    "    }\n",
    "\n",
    "mask_gpt = df['Market_True_Return'].notnull() & df['LSTM_GPT4'].notnull() # Data masks and calculated for both models\n",
    "mask_fbert = df['Market_True_Return'].notnull() & df['LSTM_FinBERT'].notnull()\n",
    "\n",
    "print(\"\\nValid rows for GPT:\", mask_gpt.sum())\n",
    "print(\"Valid rows for FinBERT:\", mask_fbert.sum())\n",
    "\n",
    "if mask_gpt.sum() == 0 or mask_fbert.sum() == 0:\n",
    "    raise ValueError(\"No valid data rows for at least one model. Check input data and merges!\")\n",
    "\n",
    "metrics_gpt = compute_all_metrics(\n",
    "    df.loc[mask_gpt, 'Market_True_Return'].values,\n",
    "    df.loc[mask_gpt, 'LSTM_GPT4'].values\n",
    ")\n",
    "metrics_finbert = compute_all_metrics(\n",
    "    df.loc[mask_fbert, 'Market_True_Return'].values,\n",
    "    df.loc[mask_fbert, 'LSTM_FinBERT'].values\n",
    ")\n",
    "\n",
    "comparison_table = pd.DataFrame({ # Table\n",
    "    \"Hybrid (FinBERT+GPT-4)\": {k: v for k, v in metrics_gpt.items() if not isinstance(v, (np.ndarray, pd.Series, list))},\n",
    "    \"FinBERT-only\": {k: v for k, v in metrics_finbert.items() if not isinstance(v, (np.ndarray, pd.Series, list))}\n",
    "})\n",
    "print(\"Model Comparison Table\")\n",
    "print(comparison_table)\n",
    "comparison_table.to_csv(\"model_performance_comparison.csv\")\n",
    "\n",
    "print(\"Confusion Matrices\") # Confusion matrices for appendix\n",
    "print(\"Hybrid (FinBERT+GPT-4):\\n\", metrics_gpt[\"Confusion_Matrix\"])\n",
    "print(\"FinBERT-only:\\n\", metrics_finbert[\"Confusion_Matrix\"])\n",
    "np.savetxt(\"hybrid_confusion_matrix.csv\", metrics_gpt[\"Confusion_Matrix\"], delimiter=\",\")\n",
    "np.savetxt(\"finbert_confusion_matrix.csv\", metrics_finbert[\"Confusion_Matrix\"], delimiter=\",\")\n",
    "\n",
    "vix_median = df[\"VIX\"].median() # Regime split (by VIX) shows model dominance in high/low volatility\n",
    "df[\"VIX_regime\"] = np.where(df[\"VIX\"] > vix_median, \"High_VIX\", \"Low_VIX\")\n",
    "def regime_metrics(regime):\n",
    "    idx = df[\"VIX_regime\"] == regime\n",
    "    gpt_metrics = compute_all_metrics(\n",
    "        df.loc[idx & mask_gpt, \"Market_True_Return\"].values, df.loc[idx & mask_gpt, \"LSTM_GPT4\"].values\n",
    "    )\n",
    "    finbert_metrics = compute_all_metrics(\n",
    "        df.loc[idx & mask_fbert, \"Market_True_Return\"].values, df.loc[idx & mask_fbert, \"LSTM_FinBERT\"].values\n",
    "    )\n",
    "    return gpt_metrics, finbert_metrics\n",
    "for regime in [\"High_VIX\", \"Low_VIX\"]:\n",
    "    gpt_metrics, finbert_metrics = regime_metrics(regime)\n",
    "    print(f\"\\n=== {regime} Regime ===\")\n",
    "    print(\"Hybrid Sharpe:\", gpt_metrics[\"Sharpe\"], \"Cumulative:\", gpt_metrics[\"Cumulative_Return\"])\n",
    "    print(\"FinBERT-only Sharpe:\", finbert_metrics[\"Sharpe\"], \"Cumulative:\", finbert_metrics[\"Cumulative_Return\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab16bf6",
   "metadata": {},
   "source": [
    "### Shortened Time-frame Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, accuracy_score,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "df_gpt = pd.read_csv(\"derived/lstm_prac_test_predictions.csv\", parse_dates=[\"Date\"])\n",
    "df_fbert = pd.read_csv(\"derived/lstm_prac_FinBERT_only_test_predictions.csv\", parse_dates=[\"Date\"])\n",
    "market_df = pd.read_csv(\"sp500_vix_data.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "df = pd.DataFrame({ # Align data by date\n",
    "    \"Date\": df_gpt[\"Date\"],\n",
    "    \"Market_Return\": df_gpt[\"Return\"],  # Use market_df[\"Return\"] if better aligned\n",
    "    \"LSTM_GPT4\": df_gpt[\"Predicted_Return\"],\n",
    "    \"LSTM_FinBERT\": df_fbert[\"Predicted_Return\"],\n",
    "})\n",
    "df = df.merge(market_df[[\"Date\", \"Return\", \"VIX\"]].rename(columns={\"Return\": \"Market_True_Return\"}), on=\"Date\", how=\"left\")\n",
    "df[\"VIX\"] = pd.to_numeric(df[\"VIX\"], errors=\"coerce\")\n",
    "\n",
    "def trading_signal_returns(true_returns, predicted_returns): # Signal-based trading returns\n",
    "    signal = np.where(predicted_returns > 0, 1, -1)  # Long/short signal\n",
    "    return signal * true_returns\n",
    "\n",
    "mask_gpt = df['Market_True_Return'].notnull() & df['LSTM_GPT4'].notnull() # Data masks and calculated for both models\n",
    "mask_fbert = df['Market_True_Return'].notnull() & df['LSTM_FinBERT'].notnull()\n",
    "\n",
    "print(\"\\nValid rows for GPT:\", mask_gpt.sum())\n",
    "print(\"Valid rows for FinBERT:\", mask_fbert.sum())\n",
    "\n",
    "if mask_gpt.sum() == 0 or mask_fbert.sum() == 0:\n",
    "    raise ValueError(\"No valid data rows for at least one model. Check input data and merges!\")\n",
    "\n",
    "metrics_gpt = compute_all_metrics(\n",
    "    df.loc[mask_gpt, 'Market_True_Return'].values,\n",
    "    df.loc[mask_gpt, 'LSTM_GPT4'].values\n",
    ")\n",
    "metrics_finbert = compute_all_metrics(\n",
    "    df.loc[mask_fbert, 'Market_True_Return'].values,\n",
    "    df.loc[mask_fbert, 'LSTM_FinBERT'].values\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "dates = df.loc[mask_gpt, 'Date'] # Align dates\n",
    "\n",
    "gpt_signal = np.where(df.loc[mask_gpt, 'LSTM_GPT4'] > 0, 1, -1) # Trading strategy returns for both models\n",
    "finbert_signal = np.where(df.loc[mask_fbert, 'LSTM_FinBERT'] > 0, 1, -1)\n",
    "\n",
    "gpt_strat_returns = gpt_signal * df.loc[mask_gpt, 'Market_True_Return'].values\n",
    "finbert_strat_returns = finbert_signal * df.loc[mask_fbert, 'Market_True_Return'].values\n",
    "\n",
    "gpt_cum_return = np.cumsum(gpt_strat_returns) # Cumulative returns\n",
    "finbert_cum_return = np.cumsum(finbert_strat_returns)\n",
    "market_cum_return = np.cumsum(df.loc[mask_gpt, 'Market_True_Return'].values)\n",
    "\n",
    "dates = df.loc[mask_gpt, 'Date'].reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(12, 5)) # Plotting cumulative returns\n",
    "plt.plot(dates, market_cum_return, label=\"Market Cumulative Return\", color='black', linewidth=2)\n",
    "plt.plot(dates, gpt_cum_return, label=\"Hybrid Cumulative Return\", color='red')\n",
    "plt.plot(dates, finbert_cum_return, label=\"FinBERT-only Cumulative Return\", color='darkorange')\n",
    "plt.title(\"Cumulative Strategy Returns Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
